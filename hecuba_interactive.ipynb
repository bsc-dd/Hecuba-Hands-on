{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Hecuba\n",
    "\n",
    "\n",
    "## Part 1\n",
    "Hecuba is built around two main data structures; `StorageObj` and `StorageDict`. The `StorageObj` is a python regular object with a set of persistent attributes, annotated as `@ClassField name type`, for example: `@ClassField myattr int`\n",
    "\n",
    "On the other hand, the `StorageDict` represents a dictionary. To describe its data model, one can write `@TypeSpec dict<<key>,value>`, where key and value follow the format `name:type`. Keep in mind that an StorageObj can have many `ClassFields` while a StorageDict will have exactly one `TypeSpec`.\n",
    "\n",
    "\n",
    "List of supported data types:\n",
    "https://github.com/bsc-dd/hecuba/wiki/1:-User-Manual#immutable-types-supported\n",
    "\n",
    "Naming conventions:\n",
    "https://github.com/bsc-dd/hecuba/wiki/1:-User-Manual#hecuba-data-classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Define data models\n",
    "\n",
    "Define a class that inherits from either `StorageObj` or `StorageDict`. Then, add a data model that uses more than one attribute for the StorageObj, or more than one value if you chose the `StorageDict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hecuba import StorageObj\n",
    "class Element(StorageObj):\n",
    "    \"\"\"\n",
    "    @ClassField atomic_number int\n",
    "    @ClassField mass double\n",
    "    @ClassField symbol str\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create one instance, using the empty constructor `MyClass()`. Add some data, and then, invoke the method `make_persistent(\"name\")`. At this point, the data will be sent to persistent storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "helium = Element()\n",
    "helium.atomic_number = 2\n",
    "helium.mass = 4.002602\n",
    "helium.symbol = \"He\"\n",
    "helium.make_persistent(\"helium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can also access the data on storage with `cqlsh`, an interface to access Cassandra which can run SQL-like commands. Run `cqlsh` from your terminal, and explore the data. Also, you can run queries from the Notebook like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "CREATE KEYSPACE my_app WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'}  AND durable_writes = true;\r\n",
      "\r\n",
      "CREATE TABLE my_app.experiment (\r\n",
      "    id int PRIMARY KEY,\r\n",
      "    x double,\r\n",
      "    y double,\r\n",
      "    z double\r\n",
      ") WITH bloom_filter_fp_chance = 0.01\r\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\r\n",
      "    AND comment = ''\r\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\r\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\r\n",
      "    AND crc_check_chance = 1.0\r\n",
      "    AND dclocal_read_repair_chance = 0.1\r\n",
      "    AND default_time_to_live = 0\r\n",
      "    AND gc_grace_seconds = 864000\r\n",
      "    AND max_index_interval = 2048\r\n",
      "    AND memtable_flush_period_in_ms = 0\r\n",
      "    AND min_index_interval = 128\r\n",
      "    AND read_repair_chance = 0.0\r\n",
      "    AND speculative_retry = '99PERCENTILE';\r\n",
      "\r\n",
      "CREATE TABLE my_app.element (\r\n",
      "    storage_id uuid PRIMARY KEY,\r\n",
      "    atomic_number int,\r\n",
      "    mass double,\r\n",
      "    symbol text\r\n",
      ") WITH bloom_filter_fp_chance = 0.01\r\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\r\n",
      "    AND comment = ''\r\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\r\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\r\n",
      "    AND crc_check_chance = 1.0\r\n",
      "    AND dclocal_read_repair_chance = 0.1\r\n",
      "    AND default_time_to_live = 0\r\n",
      "    AND gc_grace_seconds = 864000\r\n",
      "    AND max_index_interval = 2048\r\n",
      "    AND memtable_flush_period_in_ms = 0\r\n",
      "    AND min_index_interval = 128\r\n",
      "    AND read_repair_chance = 0.0\r\n",
      "    AND speculative_retry = '99PERCENTILE';\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cqlsh -e 'DESCRIBE my_app'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      " \u001b[0;1;31mstorage_id\u001b[0m                           | \u001b[0;1;35mname\u001b[0m\r\n",
      "--------------------------------------+-------------------\r\n",
      " \u001b[0;1;32m8d8e1e7a-d929-4d37-a728-09fe6157167b\u001b[0m | \u001b[0;1;33mmy_app.experiment\u001b[0m\r\n",
      " \u001b[0;1;32md4fca017-8e45-4534-ad7b-ea448e0cde03\u001b[0m | \u001b[0;1;33mmy_app.experiment\u001b[0m\r\n",
      " \u001b[0;1;32m6f6c55fa-7949-4793-a9a8-68cac424cc56\u001b[0m | \u001b[0;1;33mmy_app.experiment\u001b[0m\r\n",
      " \u001b[0;1;32mf9693a60-723c-4862-bcab-202de264262e\u001b[0m | \u001b[0;1;33mmy_app.experiment\u001b[0m\r\n",
      " \u001b[0;1;32m7c9e3490-10f1-4ae2-8ff8-9655bb214988\u001b[0m | \u001b[0;1;33mmy_app.experiment\u001b[0m\r\n",
      " \u001b[0;1;32m1994f7ac-2433-41ac-851c-69ad27db6eda\u001b[0m | \u001b[0;1;33mmy_app.experiment\u001b[0m\r\n",
      " \u001b[0;1;32m5d0d43ee-c5d4-4771-aced-d455651574e8\u001b[0m | \u001b[0;1;33mmy_app.experiment\u001b[0m\r\n",
      " \u001b[0;1;32mb15b5162-5cbe-4b7d-a769-0b107ab9c236\u001b[0m | \u001b[0;1;33mmy_app.experiment\u001b[0m\r\n",
      " \u001b[0;1;32m5fa684ff-f28d-4fcf-b5b7-4ee48ba949e7\u001b[0m | \u001b[0;1;33mmy_app.experiment\u001b[0m\r\n",
      " \u001b[0;1;32m245f44ec-d107-4f3f-a801-2890d58516e1\u001b[0m | \u001b[0;1;33mmy_app.experiment\u001b[0m\r\n",
      "\r\n",
      "(10 rows)\r\n"
     ]
    }
   ],
   "source": [
    "!cqlsh -e 'SELECT storage_id,name FROM hecuba.istorage LIMIT 10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add a method to the class definition. The method should combine multiple attributes, or the values of a given key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Element(StorageObj):\n",
    "    \"\"\"\n",
    "    @ClassField atomic_number int\n",
    "    @ClassField mass double\n",
    "    @ClassField symbol str\n",
    "    \"\"\"\n",
    "    \n",
    "    def print_info(self):\n",
    "        print(f\"Element '{self.symbol}' has an atomic number of {self.atomic_number} and {self.mass}u mass.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the object again, but this time use the same \"name\" previously used to make the data persistent. In this way, the object will be able to recover the previous data. You can also try to call the new method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element 'He' has an atomic number of 2 and 4.002602u mass.\n"
     ]
    }
   ],
   "source": [
    "helium = Element(\"helium\")\n",
    "helium.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Let's parallelize workloads\n",
    "\n",
    "Now, declare a class that inherits from `StorageDict`, and define a data model.\n",
    "\n",
    "Then, declare one instance using the persistent constructor `MyClass(\"someid\")`. Populate the object with data, let's say, with 100k to 10 Millions key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hecuba import StorageDict\n",
    "class Particles(StorageDict):\n",
    "    \"\"\"\n",
    "    @TypeSpec dict<<id:int>,x:double,y:double,z:double>\n",
    "    \"\"\"\n",
    "\n",
    "dataset = Particles(\"experiment\")\n",
    "for i in range(10**6):\n",
    "    dataset[i] = [i*10, i/0.2, i*0.5%0.8]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Hecuba object's have a generator method, `split()`, that yields subsets of the object until all data has been fetch. \n",
    "Try that, you will see that data is split randomly, but all data is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 0 has 30581\n",
      "Block 1 has 36478\n",
      "Block 2 has 28566\n",
      "Block 3 has 41303\n",
      "Block 4 has 39662\n",
      "Block 5 has 25605\n",
      "Block 6 has 25049\n",
      "Block 7 has 17128\n",
      "Block 8 has 33631\n",
      "Block 9 has 25417\n",
      "Block 10 has 23396\n",
      "Block 11 has 38444\n",
      "Block 12 has 56691\n",
      "Block 13 has 30255\n",
      "Block 14 has 22755\n",
      "Block 15 has 38362\n",
      "Block 16 has 28414\n",
      "Block 17 has 18621\n",
      "Block 18 has 29313\n",
      "Block 19 has 29780\n",
      "Block 20 has 30013\n",
      "Block 21 has 25400\n",
      "Block 22 has 30312\n",
      "Block 23 has 36659\n",
      "Block 24 has 29376\n",
      "Block 25 has 37343\n",
      "Block 26 has 45041\n",
      "Block 27 has 34817\n",
      "Block 28 has 25078\n",
      "Block 29 has 40701\n",
      "Block 30 has 20508\n",
      "Block 31 has 22758\n",
      "Block 32 has 2543\n",
      "We counted 1000000 elements.\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i, block in enumerate(dataset.split()):\n",
    "    n_elements = len(block)\n",
    "    total = total + n_elements\n",
    "    print(f\"Block {i} has {n_elements}\")\n",
    "print(f\"We counted {total} elements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "### Exercise 3 - Parallelize an Hecuba app with COMPSs\n",
    "\n",
    "We will take the program X, which runs in sequential, and add the following to make it run in parallel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
